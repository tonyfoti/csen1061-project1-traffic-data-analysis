---
title: Traffic Data Analysis
output: html_document
---

## Loading necessary libraries

```{r}
library(dplyr)
library(ggplot2)
library(tidyr)
```
## Loading the data:

```{r}
data <- read.csv('all-semi-unique.csv')
```

## Getting basic information about the data:

```{r}
glimpse(data)
View(data)
names(data)
dim(data)
```

Hence, from applying the above functions, we have a genral idea about the data: how the different records look like, the number of records (rows), the number of columns and their corresponding names.

Also let's see the number of NAs for each column:

```{r}
sapply(data, function(d) sum(is.na(d)))
```

## Cleaning the data:

Let's see the number of unique values in each column:

```{r}
sapply(data, function(d) length(unique(d)))
```

We can see now that all the "ad" columns (columns with name starting with "ad.") have only 1 unique value. Also the columns "rd.cl" and "rd.rp.type" have only 1 unique value.

Those are useless columns for our analysis. So let's remove them:

```{r}
data <- select(data, -starts_with("ad."))
data <- select(data, -c(rd.cl, rd.rp.type))
```

Now let's see the updated number of columns:

```{r}
ncol(data)
```

Let's check for duplicate rows:

```{r}
nrow(data) - nrow(unique(data))
```

We can see that there are no duplicate rows present in the dataset.

## Extra cleaning of the data:

Since all the data we are analysing are about user reports, then a unique identifier for those reports (report's comment id) presented in the column named "rd.rp.cmid" could be included only once for a single report in our dataset. So we won't have multiple records for the same report's comment. It's just useless. Hence, we could easily filter the data with unique values of the report's comment id "rd.rp.cmid".

```{r}
data <- distinct(data, rd.rp.cmid)
```

Now let's see the updated number of rows of the updated dataset:

```{r}
nrow(data)
```

As we can see, the amount of the dataset records (#rows) have clearly decreased.

## Resolving combinations

In one of our columns ('rd.nm'), we could see that it's a combination of two values; a main road and a sub-road from it. So we can split those values to two different columns ('main_road' and 'sub_road') so that we have the main road value alone, that may help us in further analysis.

```{r}
data <- separate(data, rd.nm, c("main_road", "sub_road"), ";")
```

## Calculating timings

To be able to make time-related analysis, we will change the format of the column 'crawl_date' to a more convenient format so that we can be able to extract necessary time-related info from and use it in other calculations.

```{r}
data$crawl_date <- as.POSIXct(strptime(data$crawl_date,  format="%a %b %d %H:%M:%S UTC %Y", tz="Egypt"))
glimpse(data)
```

Now we have the crawl date in a format that we can manipulate and use to make some time calculations.

We compute the reporting time (the time a report was made/submitted by a user) using the crawl date, deducting from it the time (hours and minutes) that passed since the corresponding data was crawled (presented in the respective columns 'rd.rp.hr' and 'rd.rp.mn').

Hence, we respresent the newly computed value for the actual time of reporting in a new column 'report_time'.

```{r}
data$report_time = as.POSIXct(data$crawl_date - (data$rd.rp.hr*60*60) - (data$rd.rp.mn*60))
```

We may now get rid of the columns: 'rd.rp.hr' and 'rd.rp.mn'.

```{r}
data <- select(data, -c(rd.rp.hr, rd.rp.mn))
```

We do the same for the road status updating time (the time the status of a road was updated) using also the crawl date, deducting from it the time (hours and minutes) that passed since the corresponding data was crawled (presented in the respective columns 'rd.hr' and 'rd.mn').

Hence, we respresent the newly computed value for the actual time of updating a status of a road in a new column 'road_time'.

```{r}
data$road_time = as.POSIXct(data$crawl_date - (data$rd.hr*60*60) - (data$rd.mn*60))
```

We may now get rid of the columns: 'rd.hr' and 'rd.mn'.

```{r}
data <- select(data, -c(rd.hr, rd.mn))
```

## Further analysis on the remaining columns

**rd.ri** This column is clear to be an identifier (id) for the road 'rd.nm' (which was splitted into 'main_road' and 'sub_road').

**rd.stid** This column seems to be the status (presented by id) of the road.

**rd.new** This column represents a boolean value that doesn't seem to help in the analysis. (Not clear what it does).

**rd.img** This column is clear to be describing a boolean value for the road image.

**rd.strq** This column represents a boolean value that doesn't seem to help in the analysis. (Not clear what it does).

**rd.cmrq** This column represents a boolean value that doesn't seem to help in the analysis. (Not clear what it does).

**rd.rp.nm** This column is clear to be describing the reporter's username.

**rd.rp.fullnm** This column is clear to be descrining the reporter's full name.

**rd.rp.stid** This column seems to be the status (presented by id) of the report made by the user.

**rd.rp.cm** This column seems to be the body's description of the report's comment made by the user upon reporting.

**rd.rp.rpImg** This column seems to be describing an image value (presented by id) for the report.

**rd.rp.img** This column seems to be describing an image value (presented by id) for the report (reporter).

So let's remove some of the useless columns:

```{r}
data <- select(data, -c(rd.strq, rd.cmrq, rd.rp.rpImg, rd.rp.img))
```

## Extracting the week day from the report time

```{r}
data <- mutate(data, week_day = weekdays(as.Date(data$report_time)))
```

# Calculating some frequencies

## Week days frequencies:

Let's count the number of rows/reports for each unique value of the different week day values we have in our data set.

```{r}
week_days_frequencies <- data %>% group_by(week_day) %>% summarise(frequency = length(week_day)) %>% arrange(frequency)
week_days_frequencies
```
Let's plot the result showing the frequencies where the X-Axis is for the week days and the Y-Axis is for the frequency:

```{r}
week_days_frequencies %>% ggplot(aes(x=week_day, y=frequency)) + geom_bar(stat='identity')
```

As we can see, 'Friday' is the week day that has the least number of reports. This is normal since Friday is an off day in Egypt. And 'Thursday' is the week day that has the most number of reports. This is also normal sine 'Thursday' is the last working day, and people are used to meet or go outing after work/school, hence more usage of the streets, hence more reports and usage of the App.

## Roads frequencies:

Let's count the cumber of rows/reports for each unique value of the different road values we have in our dataset.

```{r}
roads_frequencies <- data %>% group_by(main_road) %>% summarise(frequency = length(main_road)) %>% arrange(desc(frequency))
head(roads_frequencies, 10)
```

Let's plot the result showing the frequencies where the X-Axis is for the top 10 main roads and the Y-Axis is for the frequency:

```{r}
head(roads_frequencies, 10) %>% ggplot(aes(x=main_road, y=frequency)) + geom_bar(stat='identity')
```

As we can see, 'Da2ey' is the top road being reported. It is almost 3 times the frequency of the road that comes right at the second place ('Kobry 6 October'). This is maybe because it's the longest road among all others that is the most frequently used.